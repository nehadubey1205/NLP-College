{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NehaDubey_01602192021_NLP_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOR0tf5TGkikX+O4TmbCUUp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehadubey1205/NLP-college/blob/main/Copy_of_NehaDubey_01602192021_NLP_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1"
      ],
      "metadata": {
        "id": "x4SK5iTVzSeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "JbJ8q5n0YPgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read input file \n",
        "with open(\"/content/Nlp.txt\",'r') as file:\n",
        "    text = file.read().rstrip()\n",
        "    print(type(text))\n",
        "    print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0c6uYYin4pw",
        "outputId": "69f3171f-6602-4cb9-fd53-a1b42d024816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity\n",
            "recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific\n",
            "engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made\n",
            "input features carefully optimized for each task, our system learns internal representations on the\n",
            "basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for\n",
            "building a freely available tagging system with good performance and minimal computational requirements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count no. of sentence\n",
        "with open(\"/content/Nlp.txt\",'r') as file:\n",
        "    lines = len(file.readlines())\n",
        "    print('Total Number of lines:', lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg22ZOtoWCnD",
        "outputId": "600c84cd-6f6f-40d2-f0a9-cec121716c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of lines: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conver paragraph in to list\n",
        "import string\n",
        "sentence =(text.split('. ')) \n",
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG4xhBz5Xa9g",
        "outputId": "21f934c4-81c2-4589-b166-9e5c21415bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity\\nrecognition, and semantic role labeling',\n",
              " 'This versatility is achieved by trying to avoid task-specific\\nengineering and therefore disregarding a lot of prior knowledge',\n",
              " 'Instead of exploiting man-made\\ninput features carefully optimized for each task, our system learns internal representations on the\\nbasis of vast amounts of mostly unlabeled training data',\n",
              " 'This work is then used as a basis for\\nbuilding a freely available tagging system with good performance and minimal computational requirements.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count no of word\n",
        "from collections import Counter\n",
        "#r1=['My nickname is ft.jgt','Someone is going to my place']\n",
        "Counter(\" \".join(sentence).split(\" \")).items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkBD95saXOe3",
        "outputId": "0a190901-2480-4149-fbef-3a89ca22f897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('We', 1), ('propose', 1), ('a', 4), ('unified', 1), ('neural', 1), ('network', 1), ('architecture', 1), ('and', 4), ('learning', 1), ('algorithm', 1), ('that', 1), ('can', 1), ('be', 1), ('applied', 1), ('to', 2), ('various', 1), ('natural', 1), ('language', 1), ('processing', 1), ('tasks', 1), ('including', 1), ('part-of-speech', 1), ('tagging,', 1), ('chunking,', 1), ('named', 1), ('entity\\nrecognition,', 1), ('semantic', 1), ('role', 1), ('labeling', 1), ('This', 2), ('versatility', 1), ('is', 2), ('achieved', 1), ('by', 1), ('trying', 1), ('avoid', 1), ('task-specific\\nengineering', 1), ('therefore', 1), ('disregarding', 1), ('lot', 1), ('of', 4), ('prior', 1), ('knowledge', 1), ('Instead', 1), ('exploiting', 1), ('man-made\\ninput', 1), ('features', 1), ('carefully', 1), ('optimized', 1), ('for', 1), ('each', 1), ('task,', 1), ('our', 1), ('system', 2), ('learns', 1), ('internal', 1), ('representations', 1), ('on', 1), ('the\\nbasis', 1), ('vast', 1), ('amounts', 1), ('mostly', 1), ('unlabeled', 1), ('training', 1), ('data', 1), ('work', 1), ('then', 1), ('used', 1), ('as', 1), ('basis', 1), ('for\\nbuilding', 1), ('freely', 1), ('available', 1), ('tagging', 1), ('with', 1), ('good', 1), ('performance', 1), ('minimal', 1), ('computational', 1), ('requirements.', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd way to count word, first seperate sentence into word and make list\n",
        "y= text.split()\n",
        "\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZJa43SCn4mo",
        "outputId": "4ecaf656-33f1-450a-9562-0d924e262bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We',\n",
              " 'propose',\n",
              " 'a',\n",
              " 'unified',\n",
              " 'neural',\n",
              " 'network',\n",
              " 'architecture',\n",
              " 'and',\n",
              " 'learning',\n",
              " 'algorithm',\n",
              " 'that',\n",
              " 'can',\n",
              " 'be',\n",
              " 'applied',\n",
              " 'to',\n",
              " 'various',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " 'including',\n",
              " 'part-of-speech',\n",
              " 'tagging,',\n",
              " 'chunking,',\n",
              " 'named',\n",
              " 'entity',\n",
              " 'recognition,',\n",
              " 'and',\n",
              " 'semantic',\n",
              " 'role',\n",
              " 'labeling.',\n",
              " 'This',\n",
              " 'versatility',\n",
              " 'is',\n",
              " 'achieved',\n",
              " 'by',\n",
              " 'trying',\n",
              " 'to',\n",
              " 'avoid',\n",
              " 'task-specific',\n",
              " 'engineering',\n",
              " 'and',\n",
              " 'therefore',\n",
              " 'disregarding',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'prior',\n",
              " 'knowledge.',\n",
              " 'Instead',\n",
              " 'of',\n",
              " 'exploiting',\n",
              " 'man-made',\n",
              " 'input',\n",
              " 'features',\n",
              " 'carefully',\n",
              " 'optimized',\n",
              " 'for',\n",
              " 'each',\n",
              " 'task,',\n",
              " 'our',\n",
              " 'system',\n",
              " 'learns',\n",
              " 'internal',\n",
              " 'representations',\n",
              " 'on',\n",
              " 'the',\n",
              " 'basis',\n",
              " 'of',\n",
              " 'vast',\n",
              " 'amounts',\n",
              " 'of',\n",
              " 'mostly',\n",
              " 'unlabeled',\n",
              " 'training',\n",
              " 'data.',\n",
              " 'This',\n",
              " 'work',\n",
              " 'is',\n",
              " 'then',\n",
              " 'used',\n",
              " 'as',\n",
              " 'a',\n",
              " 'basis',\n",
              " 'for',\n",
              " 'building',\n",
              " 'a',\n",
              " 'freely',\n",
              " 'available',\n",
              " 'tagging',\n",
              " 'system',\n",
              " 'with',\n",
              " 'good',\n",
              " 'performance',\n",
              " 'and',\n",
              " 'minimal',\n",
              " 'computational',\n",
              " 'requirements.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count total no of  word\n",
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9yXsrPLn4jO",
        "outputId": "b09d3998-4fda-4d40-c23b-bf6644dc8e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count frequency of word\n",
        "x= pd.value_counts(np.array(y))\n",
        "x.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2cJeOPcn4fk",
        "outputId": "e5b70b93-75eb-47bc-e8c1-c8443de18151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "a                  4\n",
              "of                 4\n",
              "and                4\n",
              "to                 2\n",
              "This               2\n",
              "for                2\n",
              "basis              2\n",
              "system             2\n",
              "is                 2\n",
              "We                 1\n",
              "on                 1\n",
              "representations    1\n",
              "internal           1\n",
              "learns             1\n",
              "each               1\n",
              "our                1\n",
              "task,              1\n",
              "optimized          1\n",
              "carefully          1\n",
              "features           1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2"
      ],
      "metadata": {
        "id": "kVcG54utZbLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #stop word\n",
        " #prepare own stop word\n",
        "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"the\", \"a\",\"our\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "6sEM6MfFMxk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l3 = [x for x in y if x not in stop_words]\n",
        "len(l3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9oi4kqIMxTp",
        "outputId": "8ad3729f-e85e-449a-87df-71a79d14e40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question3\n",
        "Stemming: Write a python program that uses NLTK library to run porter stemmer."
      ],
      "metadata": {
        "id": "o2Lrq7eMhj_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "dir(ps)\n"
      ],
      "metadata": {
        "id": "jJrlZKBcn4Xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1709e6fd-8fb4-43a3-b48e-93fd6a055366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MARTIN_EXTENSIONS',\n",
              " 'NLTK_EXTENSIONS',\n",
              " 'ORIGINAL_ALGORITHM',\n",
              " '__abstractmethods__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_apply_rule_list',\n",
              " '_contains_vowel',\n",
              " '_ends_cvc',\n",
              " '_ends_double_consonant',\n",
              " '_has_positive_measure',\n",
              " '_is_consonant',\n",
              " '_measure',\n",
              " '_replace_suffix',\n",
              " '_step1a',\n",
              " '_step1b',\n",
              " '_step1c',\n",
              " '_step2',\n",
              " '_step3',\n",
              " '_step4',\n",
              " '_step5a',\n",
              " '_step5b',\n",
              " 'mode',\n",
              " 'pool',\n",
              " 'stem',\n",
              " 'vowels']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ps.stem('coder'))\n",
        "print(ps.stem('codeing'))\n",
        "print(ps.stem('code'))\n",
        "print(ps.stem('codes'))\n",
        "print(ps.stem('car'))\n",
        "print(ps.stem('caring'))\n",
        "#print(ps.stem('program'))"
      ],
      "metadata": {
        "id": "x-VEUAmFn4Ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0eacdc-3ad6-4501-f0a6-b4fa17dc9050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coder\n",
            "code\n",
            "code\n",
            "code\n",
            "car\n",
            "care\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "ps = PorterStemmer()\n",
        "words =[\"program\", \"programmer\",\"programming\",\"programs\", \"programmers\",\"university\",\"universal\",\"universe\"]"
      ],
      "metadata": {
        "id": "nWpBh_ASn6AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "  print(w, \" : \", ps.stem(w))\n",
        "  #link -https://www.turing.com/kb/stemming-vs-lemmatization-in-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpu6Xs2Un8Lj",
        "outputId": "f90ea5d6-a3a3-43e3-e222-63c18ae73135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program  :  program\n",
            "programmer  :  programm\n",
            "programming  :  program\n",
            "programs  :  program\n",
            "programmers  :  programm\n",
            "university  :  univers\n",
            "universal  :  univers\n",
            "universe  :  univers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, even though these three words(universal, university, universe) are etymologically related, their meanings are completely different."
      ],
      "metadata": {
        "id": "XMktVVyboH6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# question 4\n",
        "#all package install\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "QISvI0kbWCUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "V4-pgSVigfjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "6_zOOpNzqDv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4"
      ],
      "metadata": {
        "id": "wvXNaNzrnKbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "wn = nltk.WordNetLemmatizer\n",
        "ps = PorterStemmer()\n",
        "dir(wn)"
      ],
      "metadata": {
        "id": "bvYoI5PnrlkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''The WordNet lemmatizer is a lexical database that is used by all the major search engines. \n",
        "It is also used in IR research projects.\n",
        " It provides lemmatization features and is a popular lemmatizer.'''\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "words2 =[\"plays\", \"playing\",\"played\", \"player\",\"pharmacies\",\"badly\"]\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print([lemmatizer.lemmatize(word)for word in words2])\n"
      ],
      "metadata": {
        "id": "c5hBsabTtiQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6236613e-1a1a-42f6-e511-b80040b22e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['play', 'playing', 'played', 'player', 'pharmacy', 'badly']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‘plays’ and ‘pharmacies’ are converted to their root forms while the remaining terms are in their original forms. Without the parts of speech (POS tag) tag, lemmatizer assumes every word as a noun by default."
      ],
      "metadata": {
        "id": "h6sw5CbsmnWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question **5**\n",
        "\n",
        "*   POS Tagging: Write a python program that uses NLTK library to perform POS tagging in a given input sentence.\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "UO37y5wfrYHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''All libraries-> already installed'''\n",
        "#import nltk\n",
        "#nltk.download('all')\n",
        "\n"
      ],
      "metadata": {
        "id": "tt4sfzzh-rgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"\"\"Today morning, Arthur felt very good.\"\"\""
      ],
      "metadata": {
        "id": "F2EaZez_tiOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokene into words\n",
        "tokens = nltk.word_tokenize(sentence)"
      ],
      "metadata": {
        "id": "JuH3YHrOtiMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parts of speech tagging\n",
        "tagged = nltk.pos_tag(tokens)"
      ],
      "metadata": {
        "id": "vgUeWoQ4tiI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZp68cVy-aah",
        "outputId": "40c6c94f-3276-4239-f1da-289ba5c668e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Today', 'NN'), ('morning', 'NN'), (',', ','), ('Arthur', 'NNP'), ('felt', 'VBD'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "CC Coordinating Conjunction\n",
        "CD Cardinal Digit\n",
        "DT Determiner\n",
        "EX Existential There. Example: “there is” … think of it like “there exists”)\n",
        "FW Foreign Word.\n",
        "IN Preposition/Subordinating Conjunction.\n",
        "JJ Adjective.\n",
        "JJR Adjective, Comparative.\n",
        "JJS Adjective, Superlative.\n",
        "LS List Marker 1.\n",
        "MD Modal.\n",
        "NN Noun, Singular.\n",
        "NNS Noun Plural.\n",
        "NNP Proper Noun, Singular.\n",
        "NNPS Proper Noun, Plural.\n",
        "PDT Predeterminer.\n",
        "POS Possessive Ending. Example: parent’s\n",
        "PRP Personal Pronoun. Examples: I, he, she\n",
        "PRP$ Possessive Pronoun. Examples: my, his, hers\n",
        "RB Adverb. Examples: very, silently,\n",
        "RBR Adverb, Comparative. Example: better\n",
        "RBS Adverb, Superlative. Example: best\n",
        "RP Particle. Example: give up\n",
        "TO to. Example: go ‘to’ the store.\n",
        "UH Interjection. Example: errrrrrrrm\n",
        "VB Verb, Base Form. Example: take\n",
        "VBD Verb, Past Tense. Example: took\n",
        "VBG Verb, Gerund/Present Participle. Example: taking\n",
        "VBN Verb, Past Participle. Example: taken\n",
        "VBP Verb, Sing Present, non-3d take\n",
        "VBZ Verb, 3rd person sing. present takes\n",
        "WDT wh-determiner. Example: which\n",
        "WP wh-pronoun. Example: who, what\n",
        "WP$ possessive wh-pronoun. Example: whose\n",
        "WRB wh-abverb. Example: where, when'''"
      ],
      "metadata": {
        "id": "KmiOsR_t-lOr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}